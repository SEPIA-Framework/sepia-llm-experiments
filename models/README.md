# Model Download

You can find a lot of models on the Huggingface website. Please make sure you comply with the license before you download anything.  
Look for GGUF files that have been optimized and quantized for llama.cpp. Usually Q4_K_M versions are a good compromise between size and performance.  
  
Put your model files into this folder to run the server.